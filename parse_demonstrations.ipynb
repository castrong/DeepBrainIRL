{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a legacy parser for demo files recorded before January 2020\n",
      "No scene structure files\n",
      "No plotly\n"
     ]
    }
   ],
   "source": [
    "import Driving\n",
    "from Driving import NavigationDemoLogParser, FrameParsers, driveUtilities\n",
    "from Driving.NavigationDemoLogParser import NavigationDemoLogParser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_log_data(filenames):\n",
    "    \"\"\"\n",
    "        Helper function for loading data.\n",
    "        Returns a list of NavigationDemoLogParser objects corresponding to each\n",
    "        file in filenames.  \n",
    "    \"\"\"\n",
    "    # Load your simulation data using the NavigationDemoLogParser\n",
    "    navigation_parsers = [NavigationDemoLogParser(filename, autoParse=True) for filename in filenames]\n",
    "    return navigation_parsers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the data in the parser and converting it into a matrix representing the trajectory. The states will be:\n",
    "1. Ego position\n",
    "2. Ego rotation\n",
    "3. Ego speed\n",
    "4. Nearest k_vehicle vehicle positions (relative to ego)\n",
    "5. nearest k_vehicle vehicle rotations \n",
    "6. nearest k_vehicle speeds \n",
    "7. nearest k_pedestrian positions (relative to ego)\n",
    "8. nearest k_pedestrian speeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_closest(position, other_positions, other_rotations, other_speeds, k):\n",
    "    \"\"\"\n",
    "         Select the k elements of other_positions, other_rotations, and other_speeds where \n",
    "         the element of other_positions is closest to position. \n",
    "    \"\"\"\n",
    "    distances = [np.linalg.norm(position - other_position) for other_position in other_positions]\n",
    "    sorted_zipped = sorted(zip(distances, other_positions, other_rotations, other_speeds), key=lambda pair: pair[0])\n",
    "    sorted_positions = [x for _, x, _, _ in sorted_zipped]\n",
    "    sorted_rotations = [x for _, _, x, _ in sorted_zipped]\n",
    "    sorted_speeds = [x for _, _, _, x in sorted_zipped]\n",
    "\n",
    "    return sorted_positions[0:k], sorted_rotations[0:k], sorted_speeds[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_controls(parser):\n",
    "    # Set up the control matrix\n",
    "    num_points = parser.playerPosition.shape[0]\n",
    "    controls = np.zeros((num_points, 3))\n",
    "\n",
    "    # Now pull out data on the controls\n",
    "    throttles, brakes, steering_wheels, gears = parser.throttle, parser.brake, parser.steering, parser.gear\n",
    "\n",
    "    # Fill in the matrix\n",
    "    controls[:, 0] = throttles - brakes\n",
    "    controls[:, 1] = steering_wheels\n",
    "\n",
    "    return controls\n",
    "\n",
    "\n",
    "def gather_states(parser, k_closest_vehicles=5, k_closest_pedestrians=5):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" \n",
    "    delta_T = 1/parser.FPS\n",
    "\n",
    "    # Pull out all the data from the parser. start with the ego vehicle \n",
    "    positions = parser.playerPosition\n",
    "    rotations = parser.playerRotation\n",
    "    speeds = parser.speed\n",
    "\n",
    "    # Now pull out data for the other vehicles \n",
    "    vehicle_position_map = parser.vehiclePosition \n",
    "    vehicle_rotation_map = parser.vehicleRotation      \n",
    "\n",
    "    # Now pull out data for the pedestrians \n",
    "    pedestrian_position_map = parser.pedestrianPosition\n",
    "    pedestrian_rotation_map = parser.pedestrianRotation\n",
    "\n",
    "    # Now pull out data on the controls \n",
    "    throttles, brakes, steering_wheels, gears = parser.throttle, parser.brake, parser.steering, parser.gear\n",
    "\n",
    "    # Create the state and control matrices\n",
    "    num_points = positions.shape[0]\n",
    "    states = np.zeros((num_points, 7 + 7*k_closest_vehicles + 7*k_closest_pedestrians))\n",
    "    controls = np.zeros((num_points, 3))\n",
    "\n",
    "    # Fill in the state and control matrix indices that we can \n",
    "    states[:, 0:3] = positions\n",
    "    states[:, 3:6] = rotations\n",
    "    states[:, 6] = speeds\n",
    "\n",
    "    # assert that if throttles is non-zero then brakes must be 0 and vice versa\n",
    "    assert np.all(np.logical_or(throttles == 0, brakes == 0))\n",
    "\n",
    "    for i in tqdm(range(num_points)):\n",
    "        position, rotation, speed = positions[i, :], rotations[i, :], speeds[i]\n",
    "\n",
    "        # Gather the vehicle states \n",
    "        vehicle_positions = []\n",
    "        vehicle_rotations = []\n",
    "        vehicle_speeds = [] # estimate these based off of previous moment \n",
    "        for vehicle in vehicle_position_map.keys():\n",
    "            vehicle_exists = not np.isnan(vehicle_position_map[vehicle][i, 0])\n",
    "            if vehicle_exists:\n",
    "                vehicle_positions.append(vehicle_position_map[vehicle][i, :] - position) # relative to ego vehicle\n",
    "                vehicle_rotations.append(vehicle_rotation_map[vehicle][i, :])\n",
    "\n",
    "                # Estimate and add speed as well \n",
    "                speed_estimate = 0 if i == 0 else (vehicle_position_map[vehicle][i, :] - vehicle_position_map[vehicle][i, :]) / delta_T\n",
    "                vehicle_speeds.append(speed_estimate)\n",
    "            \n",
    "        # Select only the closest vehicles to retain \n",
    "        vehicle_positions, vehicle_rotations, vehicle_speeds = select_closest(position, vehicle_positions, vehicle_rotations, vehicle_speeds, k_closest_vehicles)\n",
    "        \n",
    "        # Gather the pedestrian states\n",
    "        pedestrian_positions = [] \n",
    "        pedestrian_rotations = []\n",
    "        pedestrian_speeds = []\n",
    "        pedestrian_exists = []\n",
    "        for pedestrian in pedestrian_position_map.keys():\n",
    "            pedestrian_exists = not np.isnan(pedestrian_position_map[pedestrian][i, 0])\n",
    "            if pedestrian_exists:\n",
    "                pedestrian_positions.append(pedestrian_position_map[pedestrian][i, :] - position) # relative to ego vehicle \n",
    "                pedestrian_rotations.append(pedestrian_rotation_map[pedestrian][i, :])\n",
    "\n",
    "                # Estimate and add speed as well \n",
    "                speed_estimate = 0 if i == 0 else (pedestrian_position_map[pedestrian][i, :] - pedestrian_position_map[pedestrian][i, :]) / delta_T\n",
    "                pedestrian_speeds.append(speed_estimate)\n",
    "\n",
    "        # Select only the closest pedestrians to retain \n",
    "        pedestrian_positions, pedestrian_rotations, pedestrian_speeds = select_closest(position, pedestrian_positions, pedestrian_rotations, pedestrian_speeds, k_closest_pedestrians)\n",
    "        \n",
    "        # Fill in the state matrix appropriately \n",
    "        states[i, 7:7+3*k_closest_vehicles] = np.concatenate(vehicle_positions)\n",
    "        states[i, 7+3*k_closest_vehicles:7+6*k_closest_vehicles] = np.concatenate(vehicle_rotations)\n",
    "        states[i, 7+6*k_closest_vehicles:7+7*k_closest_vehicles] = np.concatenate(vehicle_speeds)\n",
    "\n",
    "        states[i, 7+7*k_closest_vehicles:7+7*k_closest_vehicles+3*k_closest_pedestrians] = np.concatenate(pedestrian_positions)\n",
    "        states[i, 7+7*k_closest_vehicles+3*k_closest_pedestrians:7+7*k_closest_vehicles+6*k_closest_pedestrians] = np.concatenate(pedestrian_rotations)\n",
    "        states[i, 7+7*k_closest_vehicles+6*k_closest_pedestrians:7+7*k_closest_vehicles+7*k_closest_pedestrians] = np.concatenate(pedestrian_speeds)\n",
    "\n",
    "\n",
    "    return states\n",
    "\n",
    "def load_scenario_label(filename):\n",
    "    data = np.load(filename)\n",
    "    timestamps = data['timestamps']\n",
    "    labels = data['labels']\n",
    "    return timestamps, labels\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the files we'd like to load for train, test, and validation. Then, load the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the files for your train, validation, and test sets\n",
    "train_filenames = [\"./Data/LogAndLabelData/20210126SP_13-52-24_positions.xml\"]\n",
    "validation_filenames = [\"./Data/LogAndLabelData/20210126SP_14-08-22_positions.xml\"]\n",
    "test_filenames = [\"./Data/LogAndLabelData/20210126SP_14-23-30_positions.xml\"]\n",
    "\n",
    "# Load the appropriate parsers for each of the files\n",
    "train_parsers = load_log_data(train_filenames)\n",
    "validation_parsers = load_log_data(validation_filenames)\n",
    "test_parsers = load_log_data(test_filenames)\n",
    "\n",
    "# Gather the state and control matrices for each of the files\n",
    "train_trajectories = [(gather_states(parser), gather_controls(parser)) for parser in train_parsers]\n",
    "validation_trajectories = [(gather_states(parser), gather_controls(parser)) for parser in validation_parsers]\n",
    "test_trajectories = [(gather_states(parser), gather_controls(parser)) for parser in test_parsers]\n",
    "\n",
    "# Also load the scenario labels \n",
    "train_labels = [load_scenario_label(filename) for filename in train_filenames]\n",
    "validation_labels = [load_scenario_label(filename) for filename in validation_filenames]\n",
    "test_labels = [load_scenario_label(filename) for filename in test_filenames]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'd like to pull out only the various straight segments from the trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_time_to_log_sample(parser, video_time):\n",
    "    \"\"\" \n",
    "        Given a video time, return the corresponding log sample. \n",
    "    \"\"\"\n",
    "    # The time that data starts at. \n",
    "    start_time = parser.firstTRFrame / parser.FPS\n",
    "    # The index will be given by the time elapsed since data started being captured\n",
    "    # scaled by the data rate (parser.FPS)\n",
    "    return (video_time - start_time) * parser.FPS\n",
    "\n",
    "def get_straight_demonstrations(parsers, trajectories, labels):\n",
    "    \"\"\" \n",
    "        Given a list of trajectories, use the labels to pull out separate \n",
    "        sub-trajectories corresponding to each straight segment. \n",
    "    \"\"\"\n",
    "\n",
    "    sub_trajectories = []\n",
    "    for (parser, trajectory, (timestamps, labels)) in zip(parsers, trajectories, labels):\n",
    "        for (i, label) in enumerate(labels):\n",
    "            if label == 'straight':\n",
    "                start_time = timestamps[i]\n",
    "                end_time = timestamps[i+1]\n",
    "\n",
    "                # Find the indices corresponding to the start and end times. \n",
    "                # note that these are start and end times from the video. \n",
    "                start_index = video_time_to_log_sample(parser, start_time)\n",
    "                end_index = video_time_to_log_sample(parser, end_time)\n",
    "\n",
    "                # index into the states and controls, and then append to our growing list \n",
    "                # of sub-trajectories\n",
    "                sub_states = trajectory[0][start_index:end_index, :]\n",
    "                sub_controls = trajectory[1][start_index:end_index, :]\n",
    "                sub_trajectories.append((sub_states, sub_controls))\n",
    "\n",
    "    return sub_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper function above to load each straight segment of the trajectories as a separate \n",
    "# demonstration\n",
    "train_demonstrations = get_straight_demonstrations(train_parsers, train_trajectories, train_labels)\n",
    "validation_demonstrations = get_straight_demonstrations(validation_parsers, validation_trajectories, validation_labels)\n",
    "test_demonstrations = get_straight_demonstrations(test_parsers, test_trajectories, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the demonstrations to file\n",
    "np.save(\"./Data/train_demonstrations.npy\", train_demonstrations)\n",
    "np.save(\"./Data/validation_demonstrations.npy\", validation_demonstrations)\n",
    "np.save(\"./Data/test_demonstrations.npy\", test_demonstrations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HRIFinalProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
